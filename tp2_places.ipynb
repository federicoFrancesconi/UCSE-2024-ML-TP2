{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d44bcb2-9c95-46a3-84db-a73f8f435361",
   "metadata": {},
   "source": [
    "# Machine Learning - TP2: Detectando lugares del mundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ded9f-e152-4e88-8915-94da2ac7152c",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afee0ff-6924-414c-b346-4ef6ca0bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a93e395-6868-42b9-9894-b872e2ad4238",
   "metadata": {},
   "source": [
    "### Origen de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c98d3-375d-45b7-ab83-76f70e31733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fede: /media/federico/secondary/Repositorios/UCSE/MachineLearning/data_tp2/\n",
    "# Andy: C:/Users/andru/Downloads/ucse-ia-2024-tp-2-clasificacion-de-imagenes/\n",
    "BASE_DIR = 'C:/Users/andru/Downloads/ucse-ia-2024-tp-2-clasificacion-de-imagenes/'\n",
    "\n",
    "TRAIN_DIR = Path(BASE_DIR + 'train')\n",
    "TEST_DIR = Path(BASE_DIR + 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8c0c2-42f9-4d07-ae37-61595e094f7e",
   "metadata": {},
   "source": [
    "### Variables Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889e2df-f2e4-416b-9120-1a727009a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASES = \"street\", \"sea\", \"mountain\", \"glacier\", \"forest\", \"buildings\"\n",
    "SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3e4cd-da57-41d3-b856-586f4a16190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reader = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=10,\n",
    "    #width_shift_range=0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    ")\n",
    "\n",
    "READ_PARAMS = dict(\n",
    "    class_mode=\"categorical\",  # tenemos N labels, queremos tuplas de 0s y 1s indicando cuál de los labels es\n",
    "    classes=CLASES,  # para usar el mismo orden en todos lados\n",
    "    target_size=(SIZE, SIZE),  # para que corra más rápido, vamos a achicar las imágenes\n",
    "    color_mode=\"rgb\",  # queremos trabajar con las imágenes a color\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74275c-fc07-4e48-8356-545aac315b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b744b-9762-42d3-8623-0b8c07d9494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = next(dataset)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(CLASES[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef753897-bf6a-4390-be5d-080e66eb2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4604e-a9d1-4d61-8125-594fabd1257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in train:\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(x_batch[i])\n",
    "        plt.title(f\"Class: {CLASES[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    mean = np.mean(x_batch, axis=(0, 1, 2))\n",
    "    std = np.std(x_batch, axis=(0, 1, 2))\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    channels = ['R', 'G', 'B']\n",
    "    \n",
    "    plt.bar(channels, mean, color='skyblue', label='Media')\n",
    "    plt.errorbar(channels, mean, yerr=std, fmt='o', color='red', label='Desviación Estándar', capsize=5)\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(\"Media y Desviación Estándar por Canal\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8824f-33c5-4a3d-979e-5224bb898d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "contador_imagenes = {}\n",
    "for subcarpeta, _, _ in os.walk(TRAIN_DIR):\n",
    "    imagenes = tf.io.gfile.glob(os.path.join(subcarpeta, \"*.jpg\"))\n",
    "    contador_imagenes[subcarpeta] = len(imagenes)\n",
    "\n",
    "clasesplt = []\n",
    "cantidades = []\n",
    "\n",
    "for clase, cantidad in contador_imagenes.items():\n",
    "        partes = clase.split('\\\\')\n",
    "        clases = partes[-1].split(\".\")[0]      \n",
    "        clasesplt.append(clases)\n",
    "        cantidades.append(cantidad)\n",
    "\n",
    "clasesplt.pop(0)\n",
    "cantidades.pop(0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(clasesplt, cantidades, color='skyblue')\n",
    "plt.xlabel('Clases')\n",
    "plt.ylabel('Cantidad de Imágenes')\n",
    "plt.title('Cantidad de Imágenes por Clase')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905690e-1c64-46d6-9742-949e317fa17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
